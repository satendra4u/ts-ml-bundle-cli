# {{ project_name|title }} - Databricks ML Platform

**Model Type:** {{ model_type|title }}  
**Generated with:** ts-ml-bundle CLI  

This project follows Databricks ML Platform governance and best practices for {{ model_type }} models.

## Project Structure

```
{{ project_name }}/
├── databricks.yaml          # Bundle configuration
├── requirements.txt         # Dependencies
├── requirements-lock.txt    # Pinned versions
├── src/
│   └── ds/                  # Main package
│       ├── preprocess.py    # Data preprocessing
│       ├── train.py         # Model training
│       ├── register.py      # Model registration
│       ├── deploy_serving.py # Serving deployment
│       └── utils/
│           ├── io.py        # UC table I/O helpers
│           └── mlflow_utils.py # MLflow utilities
├── notebooks/
│   ├── 01_preprocess.py     # Interactive preprocessing
│   ├── 02_train.py          # Interactive training
│   └── 03_register_and_validate.py
├── jobs/
│   ├── job_preprocess.yml   # Job definitions
│   ├── job_train.yml
│   ├── job_register.yml
│   ├── job_deploy_serving.yml
│   └── job_batch_inference.yml
├── policies/
│   ├── cluster_policy_restricted.json
│   └── serving_policy_serverless.json
├── ci/
│   └── github-actions.yml   # CI/CD pipeline
└── docs/
    └── GOVERNANCE.md        # Governance documentation
```

## Quick Start

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure Databricks CLI:**
   ```bash
   databricks configure
   ```

3. **Validate and deploy:**
   ```bash
   databricks bundle validate --target dev
   databricks bundle deploy --target dev
   ```

4. **Run the ML pipeline:**
   ```bash
   # Preprocess data
   databricks jobs run-now --job-name {{ project_name_underscore }}-01-preprocess
   
   # Train model
   databricks jobs run-now --job-name {{ project_name_underscore }}-02-train
   
   # Register model
   databricks jobs run-now --job-name {{ project_name_underscore }}-03-register
   
   # Deploy serving endpoint
   databricks jobs run-now --job-name {{ project_name_underscore }}-04-deploy-serving
   ```

## Configuration

- **Workspace:** {{ workspace_host }}
- **Model Type:** {{ model_type|title }}
- **GPU Support:** {% if use_gpu %}Enabled{% else %}Disabled{% endif %}

## Governance Features

- ✅ Multi-environment support (dev/stg/prod)
- ✅ Unity Catalog integration
- ✅ Quality gates and approvals
- ✅ Cluster policies and security
- ✅ MLflow experiment tracking
- ✅ CI/CD pipeline with GitHub Actions

## Next Steps

1. Update Unity Catalog schema names in `databricks.yaml`
2. Configure service principals for each environment
3. Set up GitHub repository and secrets for CI/CD
4. Customize the model training logic in `src/ds/train.py`

For detailed governance documentation, see `docs/GOVERNANCE.md`.